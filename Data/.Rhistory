View(mammals)
View(email50)
email50 %>%
count(sent,spam)
#count
email50 %>%
count(sent_email,spam)
######
data(weather)
install.packages("xlsx")
library(xlsx)
library(xlsx)
install.packages("readxl")
install.packages("tidyr")
library(tidyr)
# TIDY DATA ###########################################
# DATA CLASSES
# character: "treatment" = name of variable
# numeric: 23.44, 120, NaN, Inf
# integer: 4L, 111L
# factor: factor("Hello"), "factor(8)" for categorical variables
# logical: TRUE, FALSE, NA
# CHANGE DATA CLASS
as.character(2016)
as.numeric(TRUE)
library(lubridate)
install.packages("lubridate")
library(lubridate)
ymd("2020-04-04")
mdy("August 25, 2015"")
mdy("August 25, 2015")
mdy("August 25, 2015")
hms("13:33:09")
6*8
#VARIABLES
#no spaces, separate with periods, dont start with number, case sensitive
#assignment of variable with = or <-
ls()  #see all the variables in current R session
#VECTORS
c(2,3,5,8,24)
Country = c("Brazil", "China", "India", 'Switzerland","USA")
Country = c("Brazil", "China", "India", 'Switzerland","USA")
LifeExpectancy = c(74,75,76,77.78)
Country = c("Brazil", "China", "India", 'Switzerland","USA")
Country [1]
LifeExpectancy = c(74,75,76,77.78)
Country = c("Brazil", "China", "India", "Switzerland","USA")
Country [1]
seq(0,100,2)
#DATA FRAMES
CountryData = data.frame(Country, LifeExpectancy)
#VECTORS
#do not combine diverse classes in one vector
c(2,3,5,8,24) #combine
Country = c("Brazil", "China", "India", "Switzerland","USA")
Country
Country [1]
Country
install.packages("rugarch")
Country [1]
Country [1]
Country [1]
Country = c("Brazil", "China", "India", "Switzerland","USA")
Country [1]
LifeExpectancy = c(74,75,76,77.78)
seq(0,100,2) #beginning, end, step
#DATA FRAMES
CountryData = data.frame(Country, LifeExpectancy)
LifeExpectancy = c(74,75,76,77,78)
#DATA FRAMES
CountryData = data.frame(Country, LifeExpectancy)
#DATA FRAMES
CountryData = data.frame(Country, LifeExpectancy)
LifeExpectancy[1]
#DATA FRAMES
CountryData = data.frame(Country, LifeExpectancy)
CountryData
CountryData$Population = c(199,139,124,0.799,318)
CountryData
Country = c("Australia", "Greece")
LifeExpectancy = c(82,83)
Population= c(230, 220)
NewCountryData = data.frame(Country, LifeExpectancy, Population)
#Combine data.frames
AllCountryData = rbind(CountryData, NewCountryData)
AllCountryData
setwd("~/Desktop/Future/Ultimate R")
getwd()
WHO = read.csv("WHO.csv")
setwd("~/Desktop/Future/Ultimate R/Data")
WHO = read.csv("WHO.csv")
str(WHO)
summary(WHO)
WHO_Europe = subset(WHO, Region == "Europe")
str(WHO_Europe)
write.csv(WHO_Europe,"WHO_Europe.csv")
ls()
rm(WHO_Europe)
ls()
WHO$Under15
mean(WHO$Under15)
sd(WHO$Under15)
which.min(WHO$Under15)
which.min(WHO$Under15,WHO$Country)
WHO$Country[86]
which.max(WHO$Under15)
WHO$Country[124] #verify which country
plot(WHO$GNI,WHO$FertilityRate)
Outliers = subset(WHO,GNI > 10000 & FertilityRate >2.5)
Outliers()
str(Outliers)
nrow(Outliers)
Outliers [c("Country","GNI", "FertilityRate")]
mean(WHO$Over60)
which.min(WHO$Over60)
WHO$Country[183]
which.max(WHO$LiteracyRate)
WHO$Country[44]
hist(WHO$CellularSubscribers)
boxplot(WHO$LifeExpectancy ~ WHO$Region)
boxplot(WHO$LifeExpectancy ~ WHO$Region, xlab = "", ylab = "Life Expectancy" )
table(WHO$Region)
tapply(WHO$Over60, WHO$Region, mean)
tapply(WHO$LiteracyRate, WHO$Region, mean, na.rm=TRUE)
tapply(WHO$ChildMortality, WHO$Region, mean)
CLC
clc
cat("\014")
USDA <-read.csv("USDA.csv")
USDA <-read.csv("USDA.csv")
USDA <-read.csv("USDA.csv")
str(USDA)
#Find the observation
caviarNa = match("CAVIAR", USDA$Description, USDA$Sodium)
#Find the observation
caviarNa = match("CAVIAR", USDA$Description)
#Find the observation
caviarNa = match("CAVIAR", USDA$Description)
#Find the observation
match("CAVIAR", USDA$Description)
USDA$Sodium [4154]
#Find the observation
USDA$Sodium[match("CAVIAR", USDA$Description)]
mean (USDA$Sodium)
mean (USDA$Sodium, na.rm = TRUE)
median (USDA$Sodium, na.rm = TRUE)
plot(USDA$Protein, USDA$TotalFat)
plot(USDA$Protein, USDA$TotalFat, xxlab = "Protein", ylab = "Fat")
plot(USDA$Protein, USDA$TotalFat, xlab = "Protein", ylab = "Fat")
plot(USDA$Protein, USDA$TotalFat, xlab = "Protein", ylab = "Fat", main = "Protein vs. Fat", col = "red")
hist(USDA$VitaminC, xlab = Vitamin c, main = "Vitamin C levels"")
hist(USDA$VitaminC, xlab = "Vitamin C", main = "Vitamin C levels"")
hist(USDA$VitaminC, xlab = "Vitamin C", main = "Vitamin C levels")
hist(USDA$VitaminC, xlab = "Vitamin C", main = "Vitamin C levels")
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Vitamin C levels", xlim = 500)
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Vitamin C levels", xlim = "500")
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Vitamin C levels", xlim = c(0,100))
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Vitamin C levels", xlim = c(0,100,1))
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Vitamin C levels", xlim = c(0,100), breaks=100)
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Vitamin C levels", xlim = c(0,100), breaks=2000) #breaks
boxplot(USDA$S)
boxplot(USDA$Sugar)
boxplot(USDA$Sugar, main = "Boxplot of Sugar Levels", ylab ="Sugar (g)")
#Add new variable that shows 1 if sodium < mean, 0 otherwise
USDA$HighSodium = as.numeric (USDA$Sodium > mean(USDA$Sodium), na.rm = TRUE)
#Add new variable that shows 1 if sodium < mean, 0 otherwise
USDA$HighSodium = as.numeric (USDA$Sodium > mean(USDA$Sodium, na.rm = TRUE)
#Add new variable that shows 1 if sodium < mean, 0 otherwise
USDA$HighSodium = as.numeric (USDA$Sodium > mean(USDA$Sodium, na.rm = TRUE))
#Add new variable that shows 1 if sodium < mean, 0 otherwise
USDA$HighSodium = as.numeric (USDA$Sodium > mean(USDA$Sodium, na.rm = TRUE))
str(USDA)
USDA$HighProtein = as.numeric (USDA$Protein > mean(USDA$Protein, na.rm = TRUE))
USDA$HighFat = as.numeric (USDA$Fat > mean(USDA$Fat, na.rm = TRUE))
USDA$HighProtein = as.numeric (USDA$Protein > mean(USDA$Protein, na.rm = TRUE))
USDA$HighFat = as.numeric (USDA$Fat > mean(USDA$Fat, na.rm = TRUE))
str(USDA)
USDA$HighTotalFat = as.numeric (USDA$TotalFat > mean(USDA$TotalFat, na.rm = TRUE))
#Which foods have value 1 in high Fat?
tapply(USDA$Description, USDA$HighTotalFat == 1)
#Which foods have value 1 in high Fat?
tapply(USDA$HighTotalFat == 1, USDA$Description)
#Which foods have value 1 in high Fat?
as.character(tapply(USDA$HighTotalFat == 1, USDA$Description))
#Which foods have value 1 in high Fat?
table(USDA$HighSodium)
table(USDA$HighSodium, HighTotalFat)
table(USDA$HighSodium, USDA$HighTotalFat)
#tapply (arg1, arg2, arg3) - group argumnet 1 by argument 2 and apply argument 3
tapply(USDA$Iron, USDA$HighProtein, mean, na.rm = TRUE)
USDA$HighCarbohydrate = as.numeric (USDA$Carbohydrate > mean(USDA$Carbohydrate, na.rm = TRUE))
#max level of vitamin C in HIGH and LOW CARB foods
tapply(USDA$VitaminC, USDA$HighCarbohydrate, max)
#max level of vitamin C in HIGH and LOW CARB foods
tapply(USDA$VitaminC, USDA$HighCarbohydrate, max, na.rm = TRUE)
tapply(USDA$VitaminC, USDA$HighCarbohydrate, summery, na.rm = TRUE)
tapply(USDA$VitaminC, USDA$HighCarbohydrate, summary, na.rm = TRUE)
# Test: FBI
mvt = read.csv("mvtWeek1.csv")
str(mvt)
max (mvt$ID)
min (mvt$Beat)
count(mvt$Arrest)
table(mvt$Arrest)
table(mvt$LocationDescription)
table(mvt$LocationDescription == "ALLEY")
mvt$Date
DateConvert = as.Date(strptime(mvt$Date, "%m/%d/%y %H:%M"))
summary(DateConvert)
str(DateConvert)
mvt$Month = months(DateConvert)
mvt$Weekday = weekdays(DateConvert)
mvt$Date = DateConvert
mvt$month
table (mvt$month)
table (mvt$Month)
table (mvt$Weekday)
tapply(mvt$Arrest, mvt$Month, max)
tapply(mvt$Month, mvt$Arrest, max)
as.numeric(tapply(mvt$Month, mvt$Arrest, max))
#Exercise 2: MAX level of vitamin C in HIGH and LOW CARB foods
tapply(USDA$VitaminC, USDA$HighCarbohydrate, max, na.rm = TRUE)
tapply(mvt$Month, mvt$Arrest, max)
mvt$Month
table(mvt$Month)
table(mvt$Arrest)
tapply(mvt$Month, mvt$Arrest, summary)
tapply(mvt$Month, mvt$Arrest, max)
tapply(mvt$Month, mvt$Arrest, min)
table(mvt$Arrest)
table(mvt$Month, mvt$Arrest)
hist(mvt$Date, breaks=100)
hist(mvt$Date, breaks=100)
hist(mvt$Date, breaks = 100)
hist(mvt$Date, breaks = 50)
hist(mvt$Date, breaks = 1000)
hist(mvt$Date, breaks = 1000)
boxplot(mvt$Date, mvt$Arrest)
boxplot(mvt$Arrest, mvt$Date)
boxplot(mvt$Date, mvt$Arrest)
boxplot(WHO$LifeExpectancy ~ WHO$Region) #shows box of 1st-3rd quantile spead & outliers as dots (if distance from 1st quartile is larger than 3rd minus 1st quartile)
boxplot(mvt$Date ~ mvt$Arrest)
boxplot(mvt$Date ~ mvt$Arrest)
table(mvt$Arrest)
prop.table(mvt$Arrest)
table(prop.test(mvt$Arrest))
cat("\014")
table(mvt$Arrest)
prop.table(mvt$Arrest)
prop.table(table(mvt$Arrest))
prop.table(table(mvt$Arrest, mvt$Year)) # % instead of count in table
prop.table(table(mvt$Arrest, mvt$Year == "2001")) # % instead of count in table
table(mvt$Year == "2001")
?table
table(mvt$Arrest, mvt$Year)
1212/(1212+13068)
550/(550+12542)
550/(550+13542)
sort(table(mvt$LocationDescription))
Top5 = subset(mvt, "STREET"|"PARKING LOT/GARAGE(NON.RESID.)"|"ALLEY"|"GAS STATION"|"DRIVEWAY - RESIDENTIAL")
Top5 = subset(mvt,LocationDescription == "STREET"|"PARKING LOT/GARAGE(NON.RESID.)"|"ALLEY"|"GAS STATION"|"DRIVEWAY - RESIDENTIAL")
156564+4573+2308+2111+1675
156564+14852+2308+2111+1675
Top5 = subset(mvt,LocationDescription == "STREET"|LocationDescription ==  "PARKING LOT/GARAGE(NON.RESID.)"| LocationDescription == "ALLEY"|LocationDescription == "GAS STATION"|LocationDescription == "DRIVEWAY - RESIDENTIAL")
str(Top5)
Top5$LocationDescription = factor(Top5$LocationDescription)
str((Top5))
table(mvt$Arrest,mvt$LocationDescription)
table(mvt$Arrest,Top5$LocationDescription)
table(Top5$Arrest,Top5$LocationDescription)
table(Top5$LocationDescription == "Gas Station", Top5$Weekday)
table(Top5$LocationDescription == "GAS STATION", Top5$Weekday)
table(Top5$LocationDescription == "DRIVEWAY - RESIDENTIAL", Top5$Weekday)
######### REGRESSION - PREDICTING QUALITY OF WINE ######################
# overfitting - high R^2  but poor performance on unknown data
wine = read.csv("wine.csv")
str(wine
)
summary(wine)
#Regression model
model1 = lm(Price ~ AGST)
#Regression model
model1 = lm(Price ~ AGST, data=wine)
summary(model1)
#summary - Estimate (Interncept, )
#R-squared - multiple - always increases with additional ind.var., adjusted - adjusts for number of variables and may decrease if a useless variable is added
model1$residuals
SSE = sum (model1$residuals^2)
SSE()
SSE
model2 = lm (Price ~ AGST + HarvestRain, data = wine)
summary(model2)
SSE = sum(model2$residuals^2)
SSE
model3 = lm(Price ~ AGST + HarvestRain + WinterRain +Age + FrancePop, data=wine)
summary(model3)
SSE = sum(model3$residuals^2)
SSE
model2 = lm (Price ~ HarvestRain + WinterRain, data = wine)
summary(model2)
summary(model3)
model4 = lm (Price ~ AGST + HarvestRain + WinterRain, data = wine )
summary(model4)
model4 = lm (Price ~ AGST + HarvestRain + WinterRain + Age, data = wine )
model4 = lm (Price ~ AGST + HarvestRain + WinterRain + Age, data = wine )
model4 = lm (Price ~ AGST + HarvestRain + WinterRain + Age, data = wine )
summary(model4)
# 3-factor regression, removing non significant variables
model4 = lm (Price ~ AGST + HarvestRain + WinterRain + FrancePop , data = wine )
summary(model4)
# 3-factor regression, removing non significant variables
model4 = lm (Price ~ AGST + HarvestRain + WinterRain + Age , data = wine )
summary(model4)
# 2-factor regressiom
model2 = lm (Price ~ WinterRain + HarvestRain, data = wine)
summary(model2)
# Age suddenly becomes significant - caused by MULTICOLINEARITY between Age and FrancePop
cor(wine$Age, wine$FrancePop)
# Age suddenly becomes significant - caused by MULTICOLINEARITY between Age and FrancePop
plot(cor(wine$Age, wine$FrancePop)_
#
cor(wine$WinterRain, wine$Price)
# Age and FrancePop are highly correlated -0.99
cor(wine)
# PREDICTION with trained model
# training data = on which we build model, test data = new data on which we test the quality of model
wineTest = read.csv("wine_test.csv")
# PREDICTION with trained model
# training data = on which we build model, test data = new data on which we test the quality of model
wineTest = read.csv("wine_test.csv")
str(wineTest)
predictTest = predict(model4,newdata = wineTest)
preditTest
predictTest
SSE = (wineTest$Price - predictTest)
SSE
SSE = sum((wineTest$Price - predictTest)^2)
SSE
SST = sum((wineTest$Price - mean(preditTest))^2)
SST = sum((wineTest$Price - mean(predictTest))^2)
SST
SST = sum((wineTest$Price - mean(wine$Price))^2)
SST
predictTest
str(wineTest)
1-(SSE/SST)
######### 3, ######################################
ClimateChange = read.csv("climate_change.csv")
str(ClimateChange)
summary(Clim)
summary(ClimateChange)
TestingSet = subset(ClimateChange, Year == "2007"&"2008")
TestingSet = subset(ClimateChange, Year == "2007"| Year == "2008")
str(TestingSet)
str(ClimateChange)
TrainingSet = ClimateChange[-c(284:308)]
str(TrainingSet)
TrainingSet = ClimateChange[ClimateChange['Year']!="2007"]
str(TrainingSet)
TrainingSet
######### 3, ######################################
climate = read.csv("climate_change.csv")
str(ClimateChange)
summary(climate)
str(climate)
train = subset(climate, Year <= 2006)
test = subset(climate, Year > 2006)
str(test)
climatelm = lm(Temp ~ MEI + CO2 + CH4 + N20 + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
climatelm = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
climate_model = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
climate_model
summary(climate_model)
cor(train)
climate_model1 = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
climate_model2 = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data=train)
climate_model2 = lm(Temp ~ MEI + N2O + TSI + Aerosols, data=train)
summary(climate_model2)
# Automated model building - find the BEST choice of VARIABLES (AKAIKE INFORMATION CRITERIA - AIC)
# AIC penalizes model for number of variables
climate_model_AIC = step(climate_model1)
summary(climate_model_AIC)
#
model_AIC = step(model3)
summary(model_AIC)
# ADD EXPLANATORY VARIABLE (5-factor regression)
model3 = lm(Price ~ AGST + HarvestRain + WinterRain +Age + FrancePop, data=wine)
# Automated model building - find the BEST choice of VARIABLES (AKAIKE INFORMATION CRITERIA - AIC)
# step(model with all the variables)
# AIC penalizes model for number of variables
model_AIC = step(model3)
summary(model_AIC)
climate_predict = predict(climate_model_AIC, newdata = test)
summarise(climate_predict)
summary(climate_predict)
climate_predict
SSE = sum((test$Temp - climate_predict)^2)
SSE
SST = sum((test$Temp - mean(test$Temp))^2)
SST
1-(SSE/SST)
pisaTrain = read.csv("pisa2009train.csv")
pisaTest = read.csv("pisa2009test.csv")
str(pisaTrain)
tapply(pisaTrain$readingScore, pisaTrain$male, mean)
summary(pisaTrain)
pisaTrain = na.omit(pisaTrain)
pisaTest = na.omit(pisaTest)
str(pisaTest)
str(pisaTrain)
# Reference - R automatically sets first in alphanbet, we want the most common
pisaTrain$raceeth = relevel(pisaTrain$raceeth, "White")
pisaTest$raceeth = relevel(pisaTest$raceeth, "White")
ImScore = lm(Y~., data = pisaTrain)
ImScore = lm(readingScore ~., data = pisaTrain)
summary(ImScore)
SSE = sum((pisaTrain$readingScore-ImScore)^2)
str(pisaTrain)
summary(ImScore)
ImScore$residuals
SSE = sum(ImScore$residuals^2)
SSE
str(pisaTrain)
RMSE = sqrt(SSE/(23))
RMSE
RMSE = sqrt(SSE/(2413))
RMSE
str(pisaTrain)
RMSE = sqrt(SSE/nrow(pisaTrain)) #RMSE adjusts for number of observations
RMSE
AB = lm(readingScore ~ grade, data=pisaTrain)
summary(AB)
summary(ImScore)
# Prediction model
predTest = predict(ImScore, newdata = pisaTest)
summary(predTest)
max(predTest)-min(predTest)
SSE = sum(predTest$residuals^2)
predTest
ImScore
SSE = sum((pisaTest$readingScore-predTest)^2)
SSE
RMSE = sqrt(SSE/nrow(predTest))
RMSE
RMSE = sqrt(SSE/nrow(pisaTest))
RMSE
mean(pisaTrain$readingScore)
SST = sum(pisaTest$readingScore-mean(pisaTrain$readingScore)^2)
SST
SST = sum((pisaTest$readingScore-mean(pisaTrain$readingScore)^2)
SST = sum((pisaTest$readingScore-mean(pisaTrain$readingScore))^2)
SST = sum((pisaTest$readingScore-mean(pisaTrain$readingScore))^2)
SST
# SSE & RMSE out-of-sample
SSE = sum(ImScore$residuals^2)
SSE = sum((pisaTest$readingScore-predTest)^2)
SST = sum((pisaTest$readingScore-mean(pisaTrain$readingScore))^2)
R = 1 - (SSE/SST)
R
FluTrain = read.csv("FluTrain.csv")
str(FluTrain)
52*7
tapply(FluTrain$ILI, FluTrain$Week, max)
max(FluTrain$ILI)
FluTrain [1]
FluTrain$Week [1]
max(FluTrain$Queries)
which.max(FluTrain$Queries)
which.max(FluTrain$Queries)
FluTrain$Week[303]
hist(FluTrain$ILI)
lof(FluTrain$ILI)
log(FluTrain$ILI)
hist(log(FluTrain$ILI))
plot(log(FluTrain$ILI))
plot(log(FluTrain$ILI), FluTrain$Queries)
cor(log(FluTrain$ILI), FluTrain$Queries)
plot(cor(log(FluTrain$ILI), FluTrain$Queries))
# Regression model of ILI based on Queries
FluTrend1 = lm(log(ILI)~Queries, data = FluTrain)
FluTrend
FluTrend1
summary(FluTrend1)
# Test data
FluTest = read.csv("FluTest.csv")
PredTest1 = exp(predict(FluTrend1, newdata = FluTest))
which(FluTest$Week == "2012-03-11 - 2012-03-17")
FluTrain$ILI[11]
FluTest$ILI[11]
PredTest1$ILI[11]
PredTest1[11]
str(PredTest1)
(FluTest$ILI[11]-PredTest1[11])/FluTest$ILI[11]
SSE = sum((FluTest$ILI-PredTest)^2)
SSE = sum((FluTest$ILI-PredTest1)^2)
RMSE = sqrt(SSE/nrow(FluTest))
RMSE
install.packages("zoo")
# Train Time Series Model
# Predicting current value of dependent var. (ILI) with PAST (LAGGED) value of INDEP.VAR.(Queries)
# lag =2 weeks (ILI values are reported with a 1-2 week lag)
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI),-2,na.pad=TRUE)
FluTrain$ILILag2 = coredata(ILILag2)
# Train Time Series Model
# Predicting current value of dependent var. (ILI) with PAST (LAGGED) value of INDEP.VAR.(Queries)
# lag =2 weeks (ILI values are reported with a 1-2 week lag)
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI),-2,na.pad=TRUE)
rlang::last_error()`
rlang::last_error()
rlang::last_error()
